# Data

## Description
Our project uses two complementary datasets from Singapore’s Housing & Development Board (HDB):
Dataset 1 — Median Resale Prices by Town, Quarter, and Flat Type (https://data.gov.sg/datasets/d_b51323a474ba789fb4cc3db58a3116d4/view)
Dataset 2 — Transaction-Level Resale Flat Prices (2017–Present)
https://data.gov.sg/datasets/d_8b84c4ee58e3cfc0ece0d773c8ca6abc/view

Both datasets are provided by the Housing and Development Board (HDB), an official government statutory board of Singapore. Whenever a flat is resold, an official resale application is filed with HDB and this data is then recorded and made publicly available online. Both datasets are updated quarterly, and we will focus on data from the past 5-10 years to capture recent trends and the impact of government cooling measures.

Although both sources relate to resale flat prices, they serve different analytical purposes, and using them together enables a more complete understanding of price dynamics. The first dataset provides aggregated median resale prices by town, quarter, and flat type, allowing us to analyze broad trends and patterns over time. The second dataset contains transaction-level data, which includes detailed information on each individual transaction instead of an aggregated value for the town. Crucially, the second dataset includes additional variables such as block number, approximate level of flat, floor area and lease remaining (Singapore's public housing is typically sold on a 99-year leasehold). This granularity allows us to quantify micro-level factors influencing resale prices, such as the impact of lease duration or floor level on pricing.

## Missing value analysis
At first glance, the first dataset appears to have NA and “-” to indicate missing values. This likely represents represents "Not Applicable/Not Available" and "No Transactions" respectively. The NA value likely means that these type of flats are not available for purchase in those neighbourhoods (Bishan & 1-Room Flats) and the "-" could mean that there are flats available but no purchases were made.

The second dataset appears to be cleaner with no obvious missing values. However, we will conduct a thorough missing value analysis and data cleaning process to ensure data integrity before proceeding with our analysis.

```{r}
# Load necessary libraries
library(tidyverse)
library(sf)
library(lubridate)
library(naniar)

# 1. Load the first Dataset: Median Resale Prices by Town, Quarter, and Flat Type
df_median_resale <- read_csv("datasets/MedianResalePricesforRegisteredApplicationsbyTownandFlatType.csv", 
               na = c("na", "-", "NA"))

# Load Singapore Geospatial Data (Planning Areas)
# We use a public GeoJSON link for Singapore Planning Areas
# If this link fails, you can download "Master Plan 2019 Planning Area Boundary" from data.gov.sg
geojson_url <- "https://raw.githubusercontent.com/yinshanyang/singapore/master/maps/2-planning-area.geojson"
sg_map <- st_read(geojson_url, quiet = TRUE) |>
  mutate(name = toupper(name)) # Standardize map names to Uppercase

# 2. Check for Missing Values
missing_summary_median <- df_median_resale |>
  summarise(across(everything(), ~ sum(is.na(.)), .names = "missing_{col}"))
print(missing_summary_median)

# 3. Clean Dataset
df_median_clean <- df_median_resale |>
  mutate(
    # Convert 'price' to numeric (this handles any remaining non-numeric values)
    price = as.numeric(price),
    # Convert 'quarter' (e.g., "2007-Q2") to a Date object
    date = yq(quarter),
    # Standardize town names to uppercase
    town = toupper(town)
  )
# 4. Preview Cleaned Data
print(head(df_median_clean))

# Remove missing values
df_median_final <- df_median_clean |>
  filter(!is.na(price))
```

```{r}
#| fig-width: 15
#| fig-height: 10

library(tidyverse)
library(naniar)

# ---------------------------------------------------------
# 1. Refined Plot: Missingness by Town
# ---------------------------------------------------------
# Since only 'price' is missing, we select only town and price.
# This makes the plot cleaner (removes 0% bars for quarter/flat_type).
df_median_clean |>
  select(town, price) |>
  gg_miss_fct(fct = town) +
  labs(title = "Percentage of Missing Prices by Town (Market Gaps)")

# ---------------------------------------------------------
# 2. Refined Plot: Missing Prices Over Time
# ---------------------------------------------------------
df_median_clean |>
  filter(is.na(price)) |> # Filter for missing rows first
  group_by(quarter, flat_type) |>
  summarise(missing_count = n(), .groups = 'drop') |>
  ggplot(aes(x = quarter, y = missing_count, fill = flat_type)) +
  geom_col() + 
  theme_minimal() +
  labs(title = "Count of Missing Prices per Quarter by Flat Type",
       y = "Number of Missing Records",
       subtitle = "High bars indicate quarters with few transactions") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# ---------------------------------------------------------
# 3. Heatmap: Town vs Flat Type
# ---------------------------------------------------------
# This visualizes your "Top 10" list in a single grid.
# Darker squares = More missing prices (More gaps in data)
df_median_clean |>
  filter(is.na(price)) |>
  count(town, flat_type) |>
  ggplot(aes(x = flat_type, y = reorder(town, n), fill = n)) +
  geom_tile() +
  scale_fill_viridis_c(option = "magma", direction = -1) +
  theme_minimal() +
  labs(title = "Heatmap of Missing Prices: Town vs. Flat Type",
       x = "Flat Type", 
       y = "Town", 
       fill = "Missing Count")
```
### Missing Data from first dataset
The missing data in the first dataset primarily arises from two scenarios: 
1. **Non-Availability of Flat Types in Certain Towns**: Some towns do not have certain flat types available for purchase. For example, Bishan does not have 1-Room flats, leading to NA values in the dataset for that combination.
2. **Lack of Transactions in Specific Quarters**: In some quarters, there were no resale transactions for certain flat types in specific towns. This results in "-" entries in the dataset, indicating that while the flat type exists in that town, no sales occurred during that period.

Plotting the graphs above helps visualize these gaps, showing which towns and flat types are most affected by missing data. Combining this with contextual knowledge of Singapore, the towns with the most missing data is Bukit Timah, Marine Parade and Central. Bukit Timah and Marine Parade are known to be more affluent areas with a higher concentration of private housing, which may explain the lack of HDB resale transactions. The Central area is also a prime location with a significant presence of private condominiums, leading to fewer HDB resale activities.

We can also begin to analyse the effects of government cooling measures on the HDB resale market through the missing data graph. This is likely an approximate inverse representation of the housing market, with peaks in missing data indicating quarters with low transaction volumes. There is noticeable increase in the 2013-2015 period, which coincides with the government's first round of cooling measures in December 2013. A sharp spike is also observed in 2020 Q2, which aligns with the onset of the COVID-19 pandemic and the associated economic uncertainties that likely led to a temporary halt in property transactions. We will see a more detailed analysis of these events on the other aspects of the housing market later in the project.

```{r}
# Load second Dataset: Transaction-Level Resale Flat Prices (2017–Present)
df_transactions <- read_csv("datasets/ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv",
                            na = c("na", "-", "NA"))

# Check for Missing Values
missing_summary_transactions <- df_transactions |>
  summarise(across(everything(), ~ sum(is.na(.)), .names = "missing_{col}"))
print(missing_summary_transactions)

# Clean Dataset
df_clean_transactions <- df_transactions |>
  mutate(
    # Ensure your column is actually named "month" (case-sensitive)
    date = ym(month),
    
    # Ensure 'resale_price' and 'floor_area_sqm' are numeric
    resale_price = as.numeric(resale_price),
    floor_area_sqm = as.numeric(floor_area_sqm),
    
    # Standardize character columns to uppercase
    town = toupper(town),
    flat_type = toupper(flat_type),
    
    # --- PARSE 'remaining_lease' ---
    lease_years = as.numeric(str_extract(remaining_lease, "\\d+(?= years)")),
    lease_months = as.numeric(str_extract(remaining_lease, "\\d+(?= months)")),
    lease_months = replace_na(lease_months, 0),
    remaining_lease_years = lease_years + (lease_months / 12),
    
    # Extract the first number (start of range)
    storey_lower = as.numeric(str_extract(storey_range, "^\\d+")),
    # Extract the last number (end of range)
    storey_upper = as.numeric(str_extract(storey_range, "\\d+$")),
    # Calculate the average
    storey_avg = (storey_lower + storey_upper) / 2,
    
    # --- NEW: Calculate Price Per Sqm ---
    price_per_sqm = resale_price / floor_area_sqm
  ) |>
  # Remove intermediate columns
  select(-lease_years, -lease_months, -storey_lower, -storey_upper)

# Preview Cleaned Data
print(head(df_clean_transactions))
```

Now that we have cleaned the second dataset, we can see that there are no missing values in any of the columns. This indicates that the dataset is relatively complete and does not require further imputation or handling of missing data. We can proceed with our analysis using the two cleaned datasets above.

```{r}
# ---------------------------------------------------------
# Save Objects for the Next QMD File
# ---------------------------------------------------------

# 1. Create a "processed_data" folder if it doesn't exist
if(!dir.exists("processed_data")) {
  dir.create("processed_data")
}

# 2. Save the cleaned dataframes as .rds files
# using write_rds() preserves column types (dates, factors) and geometry (sf)
write_rds(df_median_final, "processed_data/df_median_final.rds")
write_rds(sg_map, "processed_data/sg_map.rds")
write_rds(df_clean_transactions, "processed_data/df_clean_transactions.rds")

print("Data saved successfully to 'processed_data/' folder.")
```
